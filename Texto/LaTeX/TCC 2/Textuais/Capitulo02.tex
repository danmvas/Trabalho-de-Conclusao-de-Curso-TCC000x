\chapter{Fundamentação Teórica} 



Com o progresso tecnológico e a crescente importância de traçar conclusões valiosas em cima de dados educacionais, surge a necessidade de compreensão desses dados de forma cada vez mais precisa. No contexto contemporâneo, a área de \textit{Educational Data Mining} (EDM) emerge como um campo de investigação essencial, fornecendo ferramentas e técnicas destinadas a extrair conhecimentos significativos a partir das vastas quantidades de informações educacionais disponíveis. A interseção entre a mineração de dados e a educação oferece uma oportunidade única para explorar padrões, tendências e correlações dentro do ambiente educacional, possibilitando uma abordagem mais informada e personalizada para aprimorar o processo de ensino e aprendizagem. Dessa forma, a compreensão desses termos torna-se de extrema importância para a contextualização deste trabalho.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% Falar sobre o trabalho e explicar sobre o projeto ao qual o trabalho está vinculado.
% Trabalho bem grande que não está desenvolvido por inteiro
% - MEC e NEES
% - objetivo geral é tal
% - x anos
% - existem várias equipes de desenvolvimento, entrando como assistente de pesquisa

%%%%%%%%%%
  
\section{Educational Data Mining (EDM)}

\textit{Data Mining} (DM), ou mineração de dados, é um processo que envolve a descoberta de informações a partir de conjuntos de dados grandes e complexos. Seus conceitos combinam técnicas estatísticas, de banco de dados e de inteligência artificial para explorar os dados e identificar padrões, tendências e relacionamentos ocultos. A mineração de dados permite extrair conhecimentos úteis e significativos a partir de grandes volumes de dados, que podem ser provenientes de diferentes fontes, como bancos de dados corporativos, registros de transações, mídias sociais, registros de compras e muito mais. O objetivo é descobrir padrões consistentes e informações relevantes que possam ser utilizadas para tomar decisões estratégicas, identificar oportunidades de negócio, prever comportamentos futuros e melhorar a eficiência operacional.

O processo de mineração de dados envolve várias etapas, como a coleta de dados de diferentes fontes, o armazenamento em um banco de dados, o pré-processamento dos dados para garantir sua qualidade e consistência, a aplicação de técnicas de mineração de dados para descobrir padrões e relacionamentos, e a interpretação dos resultados obtidos. A mineração de dados desempenha um papel crucial em diversas áreas, tais como marketing, finanças, saúde, varejo, segurança, entre outras. Ela permite identificar segmentos de clientes, prever demandas futuras, otimizar processos, detectar fraudes, personalizar recomendações, melhorar a qualidade do atendimento ao cliente, entre muitas outras aplicações.

A \textit{Educational Data Mining}, ou mineração de dados educacionais, é uma disciplina emergente que é preocupada com o desenvolvimento de métodos para explorar os dados únicos e cada vez mais em grande escala que vêm de ambientes educacionais e usar esses métodos para entender melhor os alunos e os ambientes em que eles aprendem \cite{Egitim:2017}. Sendo assim, EDM é uma área de pesquisa interdisciplinar que combina técnicas de mineração de dados, aprendizado de máquina e estatística para analisar grandes conjuntos de dados educacionais. Seu principal objetivo é analisar dados educacionais para resolver problemas da pesquisa educacional, descobrindo padrões, tendências e relações nos dados coletados a fim de obter conclusões valiosas para melhorar a eficácia do ensino e da aprendizagem.

Através da aplicação de técnicas de mineração de dados e análise estatística, o EDM permite extrair conhecimento a partir de dados educacionais, que podem incluir registros acadêmicos, históricos de notas, interações do aluno com sistemas de aprendizagem online, dados de questionários, entre outros. Esses dados são processados e analisados para identificar padrões e relações que possam ajudar a compreender o desempenho dos alunos, suas dificuldades, preferências de aprendizagem e outros aspectos relevantes.

Alguns exemplos de aplicações do EDM incluem, mas não estão limitados a:

\begin{enumerate}
    \item Previsão do desempenho dos alunos: Ao analisar dados de sistemas educacionais, como informações dos alunos e notas, além de dados de sistemas que não estão diretamente ligados a uma universidade ou escola, como dados de vestibular do Sistema de Seleção Unificada (Sisu) ou Exame Nacional do Ensino Médio (Enem), os pesquisadores podem identificar padrões associados ao sucesso ou fracasso dos estudantes, é possível processar esses dados e identificar padrões e correlações que podem ser usados para prever o desempenho do estudantes \cite{avaandparpinelli:2020}. A previsão do desempenho dos alunos pode trazer diversos benefícios para as instituições de ensino, como a possibilidade de oferecer uma educação personalizada aos alunos de risco e o oferecimento de bolsas para alunos que se destacam.

    \item Identificação de alunos em situação de risco: Ao analisar dados sobre o comportamento e desempenho dos estudantes, os pesquisadores podem identificar fatores associados a resultados acadêmicos insatisfatórios. Por exemplo, eles podem descobrir que os alunos que faltam às aulas ou não concluem as tarefas no prazo têm maior probabilidade de abandonar a escola. Essas informações podem ser utilizadas para desenvolver sistemas de alerta precoce que informam os educadores quando um aluno está em risco de abandonar os estudos, permitindo que intervenham antes que seja tarde demais \cite{ramos:2020}.

    \item Acompanhar automaticamente atividades de estudantes: Ao analisar dados de registro provenientes de plataformas Learning Management Systems (LMS), os pesquisadores podem obter percepções sobre como os estudantes interagem com os materiais do curso e identificar áreas em que possam estar enfrentando dificuldades. Essas informações podem ser utilizadas para personalizar os ambientes de aprendizagem, fornecendo \textit{feedback} direcionado ou recomendações de recursos adicionais \cite{Santos2019}.

    \item Recomendar recursos de aprendizagem aos alunos com base em seu desempenho e preferências: Ao analisar dados sobre o comportamento e desempenho dos estudantes, os pesquisadores podem desenvolver algoritmos que recomendam recursos de aprendizagem específicos de acordo com as necessidades e interesses individuais de cada aluno \cite{9637207}.
\end{enumerate}

Contudo, para se realizar essas pesquisas deve-se coletar e analisar dados de estudantes que podem ser classificados como sensíveis, e portanto há importantes preocupações quanto à privacidade e segurança dos dados, uma vez que a pesquisa, caso feita sem cuidado, pode potencialmente colocar em risco informações pessoais dos estudantes. Além disso, a necessidade de habilidades especializadas para analisar grandes conjuntos de dados pode criar uma barreira para alguns educadores ou instituições que não tenham recursos ou conhecimentos especializados para usar efetivamente essa tecnologia. Outra possível desvantagem é a possibilidade de reforçar vieses existentes nos dados, o que pode perpetuar preconceitos e desigualdades ou limitar oportunidades para determinados grupos de estudantes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Learning Analytics (LA)}

\textit{Learning Analytics}, ou {analíticas de aprendizagem}, é uma área de estudo que utiliza técnicas e ferramentas analíticas para coletar, analisar e interpretar dados relacionados ao processo de aprendizagem. Envolve a aplicação de métodos quantitativos e qualitativos para obter informações útil sobre o desempenho dos estudantes, padrões de comportamento, eficácia do ensino, entre outros aspectos relacionados ao aprendizado. O objetivo principal do \textit{Learning Analytics} é melhorar a eficácia e a eficiência do processo de aprendizagem. Ao coletar dados relevantes, como desempenho acadêmico, interações em plataformas de aprendizado online, tempo gasto em atividades, feedback dos alunos, entre outros, as instituições educacionais podem identificar padrões e tendências que ajudam a entender melhor o progresso dos alunos e oferecer suporte personalizado. As técnicas de \textit{Learning Analytics} podem ser aplicadas em diversos contextos educacionais, desde escolas e universidades até plataformas de ensino online. Com base nas informações coletadas, é possível tomar decisões informadas para aprimorar o planejamento curricular, desenvolver intervenções pedagógicas, identificar necessidades de alunos em risco, personalizar a experiência de aprendizagem e avaliar a eficácia de métodos de ensino específicos.

{Segundo \citeonline{Aldowah2019}, há determinadas etapas necessárias para se conduzir um estudo de Learning Analytics (LA), as quais incluem:}

\begin{enumerate}
    \item {Definir o problema de pesquisa: O primeiro passo é identificar o problema de pesquisa que se deseja abordar. Isso pode envolver a identificação de uma questão específica relacionada ao ensino e aprendizagem que possa ser respondida por meio da análise de dados.}
    \item {Coletar dados: O próximo passo é coletar os dados necessários para responder à questão de pesquisa. Isso pode envolver a coleta de dados de várias fontes, como LMS, registros acadêmicos, questionários de alunos e outros dados relevantes.}
    \item {Pré-processar os dados: Depois que os dados são coletados, eles precisam ser pré-processados para garantir que estejam limpos e prontos para análise. Isso pode envolver a limpeza de dados ausentes ou inconsistentes, a normalização de dados e a seleção de recursos relevantes.}
    \item {Analisar os dados: O próximo passo é analisar os dados usando técnicas de aprendizado de máquina, mineração de dados e outras técnicas de análise de dados. Isso pode envolver a identificação de padrões e tendências nos dados, a criação de modelos preditivos e a realização de outras análises relevantes.}
    \item {Interpretar os resultados: Depois que os dados são analisados, os resultados precisam ser interpretados para responder à questão de pesquisa original. Isso pode envolver a identificação de relevância, a validação dos resultados e a comunicação dos resultados para as partes interessadas relevantes.}
    \item {Tomar medidas: Com base nos resultados da análise, as partes interessadas podem tomar medidas para melhorar o ensino e a aprendizagem. Isso pode envolver a implementação de intervenções específicas para alunos ou grupos de alunos, a revisão de materiais de ensino ou a melhoria de práticas de ensino.}
    
\end{enumerate}

{É notável que no processo de \textit{Learning Analytics} há grande envolvimento da coleta de dados de diversas fontes, como sistemas de gerenciamento de aprendizagem, registros de atividades dos alunos, interações em fóruns e redes sociais, entre outros. Esses dados são então analisados para identificar padrões e tendências que possam ajudar a entender melhor o comportamento dos alunos e o desempenho do sistema educacional como um todo. Uma das principais características de \textit{Learning Analytics} é a sua abordagem holística, que considera o sistema educacional como um todo. Isso significa que a análise de dados não se limita apenas ao desempenho dos alunos, mas também leva em conta fatores como o ambiente de aprendizagem, a qualidade do conteúdo, a eficácia dos métodos de ensino, entre outros.}

{Outra característica importante é a ênfase na intervenção e participação humana. Embora a análise de dados seja realizada por meio de ferramentas computacionais, a interpretação dos resultados e a tomada de decisões são feitas por professores, gestores e outros profissionais da educação \cite{Barone_2020}. Isso significa que a tecnologia é usada como uma ferramenta para apoiar a tomada de decisões, e não como um substituto para o julgamento humano. Isso é uma consideração importante pois os alunos estão em constante mudança de perfil, o que exige novas e eficazes ferramentas para auxiliar nesse processo. Sendo assim, as instituições de ensino vêm produzindo e armazenando grande quantidade de dados ao longo do tempo.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conexão entre EDM e LA}

Como visto nas seções anteriores, tanto LA quanto EDM são áreas específicas que são usadas para representar o uso e a aplicação de mineração de dados em diversos contextos educacionais. Elas estabelecem um ecossistema que pode consecutivamente coletar, processar, reportar e trabalhar com dados continuamente para melhorar o processo educacional. Contudo, as etapas de ambos os processos são diferentes.

{Ambas as áreas têm como objetivo a melhoria de processos de ensino e aprendizagem por meio da análise de dados em larga escala, de maneira sistematizada, que possam auxiliar na ampliação de processos de avaliação, compreensão de problemas e planejamento de intervenções. Segundo \citeonline{Moissa2015}, tanto quanto EDM e LA têm como objetivo analisar dados educacionais para entender o processo de ensino e aprendizagem e melhorá-lo, incluindo o uso de algoritmos de aprendizado de máquina, a análise de dados em tempo real e a aplicação de técnicas de análise de redes sociais. Seus resultados e análises podem ser aplicados no desenvolvimento de sistemas de recomendação personalizados para estudantes e professores.}

Uma das principais vantagens em se beneficiar de ambas as áreas é que isso permite aos tomadores de decisão avaliar os processos de aprendizagem dos estudantes e atender às suas diferentes necessidades de aprendizagem com base em seus comportamentos e preferências reais. Isso pode ser alcançado por meio do uso de técnicas de mineração de dados que analisam grandes conjuntos de dados para identificar padrões e tendências no comportamento dos alunos, como seu envolvimento com materiais do curso, seu desempenho em avaliações e suas interações com colegas e instrutores \cite{Cerezo2016}. Outro benefício do uso da mineração de dados educacionais e de analíticas de aprendizado é que podem fornecer um suporte inestimável ao processo de tomada de decisão. Por exemplo, a análise preditiva pode ser usada para identificar alunos que correm o risco de desistir ou fracassar em um curso, permitindo que os instrutores intervenham precocemente e forneçam suporte direcionado. Da mesma forma, as aplicações de mineração de dados podem ser usadas para identificar áreas em que os materiais do curso ou as estratégias instrucionais possam precisar ser revisados ou aprimorados \cite{Aldowah2019}.

{Apesar disso, existem algumas distinções entre as duas áreas. A EDM dá mais ênfase na análise de dados históricos e a identificação de padrões, geralmente se concentrando em dados históricos ou estruturados, como notas, frequência e dados demográficos dos alunos, se tornando mais voltada para a pesquisa acadêmica. Enquanto isso, a LA ao buscar coletar, medir, analisar e relatar os dados e seus contextos, é mais focada na análise em tempo real e na personalização da aprendizagem, podendo incluir dados não estruturados, como interações em fóruns de discussão e registros de atividades em plataformas de aprendizagem online. Pode ainda fornecer informações em tempo real aos educadores, permitindo que eles tomem decisões sobre como personalizar a aprendizagem para atender às necessidades individuais dos alunos; ou seja, apresenta etapas e ciclos em que é considerada a intervenção humana \cite{Campos2021}.}

{Independente das diferenças, as abordagens têm o potencial de oferecer suporte valioso ao processo de tomada de decisão e contribuir para o aprimoramento da educação.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Reconhecimento de padrões}

A mineração de dados abrange diversos sistemas para pré-processamento, análise e interpretação de dados. Essas estratégias podem ser divididas principalmente em duas áreas: reconhecimento de padrões e aprendizado de máquina. %Na área de Reconhecimento de Padrões, são utilizadas técnicas para identificar regularidades e padrões em conjuntos de dados, permitindo a extração de informações significativas. Essas informações podem ser usadas para tomar decisões ou fazer previsões em diferentes contextos, como análise de mercado, detecção de fraudes ou diagnósticos médicos.
A detecção de padrões em análise de dados desempenha um papel crucial na extração de informações valiosas a partir de conjuntos de dados. Essa abordagem analítica permite identificar regularidades, tendências ou estruturas subjacentes, revelando relações complexas entre variáveis e eventos \cite{Veluri2022}. O reconhecimento de padrões é realizado por meio de uma combinação de técnicas estatísticas e algoritmos de aprendizado de máquina. Esses algoritmos são treinados em conjuntos de dados previamente coletados, nos quais são expostos a exemplos de diferentes padrões e classes. Ao analisar esses exemplos, os algoritmos aprendem a identificar e generalizar padrões, permitindo a aplicação desses conhecimentos a novos dados para classificação, previsão ou tomada de decisões.

No contexto do \textit{Learning Analytics}, o reconhecimento de padrões desempenha um papel fundamental na compreensão do processo de aprendizagem. Ao examinar padrões de reprovação em um curso ou disciplina, é possível identificar características, comportamentos e fatores que estão correlacionados com um maior risco de insucesso dos alunos. Essas informações podem incluir variáveis como desempenho prévio, engajamento, participação em atividades ou interações com o material didático.

Além disso, o reconhecimento de padrões em análise de dados pode revelar correlações complexas e sutis que não seriam facilmente identificadas por meio de métodos tradicionais. Padrões de desempenho, por exemplo, podem estar relacionados a fatores como estilo de aprendizagem, habilidades específicas ou até mesmo fatores externos, como ambiente familiar ou condições socioeconômicas dos estudantes.

\subsection{Técnicas}
\label{subsec:tecnicas}

Técnicas de reconhecimento de padrões são métodos computacionais que permitem identificar regularidades ou padrões em dados. Essas técnicas são usadas para analisar e extrair informações úteis a partir de dados complexos, como imagens, sinais de áudio, séries temporais e conjuntos de dados multidimensionais. {As técnicas de reconhecimento de padrões %incluem algoritmos estatísticos, redes neurais artificiais, árvores de decisão, análise discriminante e agrupamento. Elas são amplamente utilizadas em diversas áreas, como visão computacional, processamento de sinais, bioinformática e análise de dados em geral \cite{Bishop:2007}. Estas técnicas de reconhecimento de padrões podem ser associada a \textit{Learning Analytics} pois elas podem ser usadas para extrair informações úteis dos grandes conjuntos de dados educacionais e ajudar a entender e otimizar todo o processo de aprendizagem.
são amplamente utilizadas em diversas áreas, como visão computacional, processamento de sinais, bioinformática e análise de dados em geral \cite{Bishop:2007}}. Estas técnicas de reconhecimento de padrões podem ser associada a \textit{Learning Analytics} pois elas podem ser usadas para extrair informações úteis dos grandes conjuntos de dados educacionais e ajudar a entender e otimizar todo o processo de aprendizagem.

Algumas delas incluem, mas não são limitadas a:

\begin{enumerate}
    \item {\textit{Clustering}: processo de agrupar um conjunto de objetos físicos ou abstratos em classes de objetos semelhantes. Um \textit{cluster} é uma coleção de objetos de dados que são semelhantes entre si dentro do mesmo \textit{cluster} e dissimilares em relação aos objetos em outros \textit{clusters}. Um \textit{cluster} de objetos de dados pode ser tratado coletivamente como um grupo e, portanto, considerado uma forma de compressão de dados. Um dos algoritmos de \textit{clustering} mais populares é o \textit{K-Means}, onde o usuário define inicialmente o número de clusters (k) que deseja criar. Em seguida, o algoritmo seleciona aleatoriamente k objetos do conjunto de dados como centróides iniciais. Depois disso, cada objeto de dados é atribuído ao centróide mais próximo com base em uma medida de distância, geralmente a distância euclidiana. Após a atribuição de todos os objetos de dados a um centróide, os centróides são recalculados como a média dos objetos de dados atribuídos a eles. Esse processo é repetido até que os centróides não mudem mais ou até que um número máximo de iterações seja atingido. O resultado final é um conjunto de k \textit{clusters}, onde cada \textit{cluster} é representado por seu centróide. Em contextos educacionais, o \textit{clustering} pode ser utilizado para agrupar alunos com base em seus desempenhos acadêmicos ou outras características relevantes. Por exemplo, um professor pode usar o k-means para agrupar alunos com base em suas notas em diferentes disciplinas ou em seus estilos de aprendizagem. Isso pode ajudar o professor a personalizar o ensino para cada grupo de alunos e melhorar o desempenho geral da turma. Além disso, o k-means também pode ser usado para agrupar cursos com base em suas características, como nível de dificuldade, carga horária, etc. \cite{Ali2017KMC}.

    \item \textit{Association Rules}: técnica de mineração de dados que busca identificar relações entre diferentes variáveis em um conjunto de dados, sendo frequentemente usada em educação para identificar padrões em dados de desempenho do aluno e comportamento do aluno. No contexto educacional, \citeonline{CEREZO201642} discutem que as regras de associação podem ser usadas para identificar padrões de comportamento e desempenho de estudantes, já que podem ser usadas para identificar relacionamentos entre diferentes variáveis, como dados demográficos, materiais do curso e resultados acadêmicos. Regras de associação podem ser usadas, por exemplo, para identificar quais materiais do curso estão mais fortemente associados ao sucesso ou fracasso do aluno, ou para desenvolver recomendações personalizadas para alunos com base em suas necessidades e preferências individuais.

    \item \textit{Time series}: técnica estatística que analisa dados coletados ao longo do tempo. O reconhecimento de padrões em séries temporais envolve o uso de algoritmos de reconhecimento de padrões que mapeiam automaticamente uma representação de entrada para uma categoria de saída. Existem três tipos principais de algoritmos de reconhecimento de padrões: supervisionado, não supervisionado e semi-supervisionado. No aprendizado supervisionado, um modelo funcional é usado para mapear entradas observadas para categorias de saída. Várias técnicas de construção de modelos foram desenvolvidas para esse fim, incluindo árvores de decisão, indução de regras, redes Bayesianas, raciocínio baseado em memória, máquinas de vetores de suporte (SVMs) e redes neurais. No aprendizado não supervisionado, um padrão de entrada é atribuído a uma classe desconhecida, sendo útil quando não há rótulos de classe disponíveis para o conjunto de dados. No aprendizado semi-supervisionado, um padrão de entrada é atribuído a uma das classes pré-definidas, usando tanto dados rotulados quanto não rotulados  \cite{jessica:time}. No contexto educacional, pode ser usado para analisar o desempenho acadêmico dos alunos ao longo do tempo e identificar tendências ou padrões sazonais.

    \item \textit{Sequential Pattern analysis}: técnica de análise de dados que consiste em descobrir padrões interessantes em um conjunto de sequências. Esses padrões podem ser medidos em termos de vários critérios, como frequência de ocorrência, comprimento e lucro. Dois algoritmos que envolvem essas técnicas são o \textit{Generalized Sequential Pattern} (GSP) e o Sequential Pattern Discovery using Equivalence classes (SPADE) \cite{FournierViger2017ASO}. O algoritmo GSP é um algoritmo de busca em profundidade que gera candidatos a padrões de tamanho k + 1 a partir de padrões de tamanho k, enquanto o algoritmo SPADE usa uma estrutura de árvore de prefixo para gerar candidatos a padrões.} No contexto educacional, pode ser usado para identificar sequências frequentes de comportamentos ou ações dos alunos durante o processo de aprendizagem. 
\end{enumerate}

\subsection{Algoritmos}
 
Tendo em vista que o objetivo do trabalho é a classificação de padrões de dados educacionais referentes a determinadas classes de perguntas, os algoritmos estudados e que podem ser aplicados aos dados são referentes à técnica de Clusterização e Regras de Associação. Após uma pesquisa na literatura pelos algoritmos mais relevantes para classificação de dados, foram escolhidos para comparação os seguintes modelos, pensando em representação de uma variedade de abordagens em aprendizado de máquina:

\begin{itemize}
    \item \textbf{Decision Tree (Árvores de Decisão):} modelos de aprendizado de máquina que utilizam uma estrutura de árvore para tomar decisões. Cada nó interno representa uma decisão baseada em um atributo, e cada folha representa o resultado da decisão. O processo de decisão ocorre percorrendo a árvore, seguindo os ramos de acordo com os valores dos atributos.
    \item \textbf{Random Forest:} técnica que utiliza um conjunto de árvores de decisão para realizar a classificação ou regressão. Cada árvore na floresta é treinada em uma amostra aleatória do conjunto de dados, e as previsões são combinadas através de votação (classificação) ou média (regressão). Isso ajuda a reduzir o sobreajuste e aumentar a estabilidade do modelo.
    \item \textbf{Naive Bayes Categórico:} classificador probabilístico baseado no Teorema de Bayes. A versão categórica assume que os atributos são discretos e seguem uma distribuição de probabilidade específica. Apesar da ingenuidade de assumir independência condicional entre os atributos, o Naive Bayes é eficaz e computacionalmente eficiente.
    \item \textbf{Adaptive Boosting (AdaBoost):} algoritmo de boosting que combina vários classificadores fracos para formar um classificador forte. Ele atribui pesos diferentes às instâncias no conjunto de treinamento, dando mais foco às instâncias classificadas incorretamente. Os classificadores fracos são treinados sequencialmente, e seus resultados são combinados ponderadamente para melhorar o desempenho geral.
    \item \textbf{K-Nearest-Neighboors (K-Vizinhos-Próximos):} algoritmo de aprendizado supervisionado que classifica uma instância com base nas classes de seus k vizinhos mais próximos no espaço de atributos. A escolha de k e da métrica de distância influencia a decisão de classificação. É simples de entender e implementar, mas pode ser sensível à escala dos atributos e ao valor escolhido para k.
\end{itemize}

Segundo \citeonline{livro:profelaine}, existem diversas métricas que podem ser utilizadas para avaliar a qualidade e o desempenho de um modelo de classificação que são úteis para prever a evasão de estudantes, e portanto serão as métricas que serão abordadas nesse trabalho. As métricas de análise para comparação dos dados serão: Acurácia, Precisão, Recall Score e F1 Score.

A \textbf{acurácia} é calculada como o número de predições corretas dividido pelo número total de predições. Pode ser enganosa em conjuntos de dados desbalanceados, pois dará uma impressão positiva mesmo se uma classe for muito predominante. Ela é calculada como mostra a Equação \ref{eq:acc}.

\begin{equation}
    \text{Acurácia} = \frac{\text{Verdadeiros Positivos} + \text{Verdadeiros Negativos}}{\text{Total de Instâncias}}
    \label{eq:acc}
\end{equation}

A \textbf{precisão} apresenta a capacidade do modelo de não rotular erroneamente uma instância como positiva. Calculada como verdadeiros positivos divididos pela soma de verdadeiros positivos e falsos positivos. Ela é calculada como mostra a Equação \ref{eq:prec}.

\begin{equation}
    \text{Precisão} = \frac{\text{Verdadeiros Positivos}}{\text{Verdadeiros Positivos} + \text{Falsos Positivos}}
    \label{eq:prec}
\end{equation}

O \textbf{Recall Score}, também conhecido como \textit{Sensibilidade} ou \textit{Taxa de Verdadeiros Positivos}, é calculado como verdadeiros positivos divididos pela soma de verdadeiros positivos e falsos negativos. É útil quando é crítico detectar todos os casos positivos. Essa métrica é calculada como mostra a Equação \ref{eq:recall}.

\begin{equation}
    \text{Recall} = \frac{\text{Verdadeiros Positivos}}{\text{Verdadeiros Positivos} + \text{Falsos Negativos}}
    \label{eq:recall}
\end{equation}

O \textbf{F1 Score} combina precisão e Recall em uma única métrica, sendo a média harmônica entre essas duas. Essa métrica é especialmente útil quando há um desequilíbrio significativo entre as classes, pois leva em consideração ambos os tipos de erros. Ele é calculado como mostra a Equação \ref{eq:f1}.

\begin{equation}
    \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
    \label{eq:f1}
\end{equation}

Cada métrica fornece uma perspectiva diferente sobre o desempenho do modelo. Para auxiliar a representação das comparações, foi optada por fazer uma visualização da \textbf{matriz de confusão} de cada um dos algoritmos aplicados às variáveis estudadas, que serão explicadas com mais profundidade no capítulo \ref{cap:analises-sap}. A matriz de confusão apresenta a relação das taxas de acerto entre Verdadeiros Positivos, Verdadeiros Negativos, Falsos Positivos e Falsos Negativos.

% \subsection{Visualização da informação}

% Tendo estabelecida a importância da coleta de dados, é necessário também discutir sobre como esses dados serão apresentados para garantir que não fiquem ambíguos ou confusos. A área da visualização de dados desempenha um papel fundamental nesse aspecto. A visualização de dados busca representar informações de forma gráfica e intuitiva, permitindo que os usuários compreendam e interpretem os dados de maneira mais eficiente.

% A percepção visual é uma ferramenta poderosa para os seres humanos, pois ajuda no reconhecimento de padrões complexos em dados. É possível identificar detalhes, distinguir formas e padrões com maior facilidade a partir de informações visuais do que a partir de grandes quantidades de dados numéricos. A mineração de dados simbólicos é uma área complexa que envolve a agregação de grandes quantidades de dados clássicos em uma forma mais compacta. No entanto, devido à sua estrutura complexa, a visualização desse tipo de dado enfrenta desafios adicionais. Diferente dos dados numéricos, que podem ser representados e visualizados de maneira direta, os dados simbólicos exigem técnicas especiais para serem visualizados de forma eficaz. A transformação de dados simbólicos em representações visuais compreensíveis é um desafio, pois é necessário preservar a essência dos dados enquanto se simplifica sua estrutura. No entanto, superar esses desafios é crucial, pois a visualização de dados simbólicos oferece benefícios significativos, permitindo que os analistas compreendam melhor os padrões e relacionamentos ocultos nos dados, facilitando a tomada de decisões informadas \cite{Umbleja2020}.

% {Torna-se evidente que a visualização de dados desempenha um papel fundamental na compreensão e interpretação de dados complexos, principalmente quando se pretende identificar padrões entre eles, atuando como uma ponte entre a análise de dados e a tomada de decisões informadas. Os algoritmos e técnicas discutidos fornecem ferramentas poderosas para representar informações de maneira clara, concisa e impactante, possibilitando uma visualização mais intuitiva e acessível.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussões sobre valores humanos relacionados}

Mesmo que a coleta de dados %tornou-se
tenha se tornado uma parte essencial do mundo moderno e que as técnicas descritas anteriormente se %beneficiam
beneficiem com grandes volumes de dados detalhados, à medida que coletamos cada vez mais informações sobre indivíduos e sociedades, surge a questão dos valores humanos relacionados a essa prática. A coleta de dados, quando mal administrada, pode levantar preocupações éticas, como a invasão de privacidade e o uso indevido das informações pessoais. Portanto, é crucial considerar os valores humanos fundamentais, como privacidade, autonomia e transparência, ao lidar com a coleta e o uso de dados.

Sendo assim, para a condução dessa pesquisa, é crucial não apenas assegurar que a coleta de dados não perpetue ou amplie desigualdades existentes, como vieses discriminatórios ou exclusão de determinados grupos, mas também discorrer sobre as implicações éticas para se ter certeza que os dados coletados para o trabalho foram coletados de forma ética. Devemos buscar a equidade no acesso aos dados e garantir que as informações coletadas sejam utilizadas de forma justa e imparcial, considerando os diferentes contextos e necessidades dos indivíduos e comunidades.

% \subsection{Ética em \textit{Learning Analytics}}

Para discutir os desafios éticos e de privacidade relacionados à \textit{Learning Analytics}, é necessário primeiro compreender melhor ambos os conceitos e sua relação um com o outro. Ética pode ser definida como um código moral de normas e convenções que existe na sociedade, externo à pessoa, enquanto a privacidade é uma parte intrínseca da identidade e integridade de uma pessoa \cite{Drachsler2016}. A compreensão do que constitui um comportamento ético varia ao longo do tempo e entre culturas. Por outro lado, a privacidade é contextual, ou seja, estabelece os limites da pessoa ou identidade em relação às outras entidades. Assim, a compreensão da privacidade pode variar consideravelmente, mesmo entre pessoas que pertencem à mesma cultura, mas vivem em diferentes arranjos familiares.

No uso cotidiano e no pensamento popular, há uma sobreposição significativa entre ética e privacidade, o que às vezes leva a confusões ao discutir os efeitos da \textit{Learning Analytics} em relação a ambos. Ambos os conceitos podem ser abordados de várias perspectivas, especialmente sociológica, psicológica, filosófica e religiosa. Eles se manifestam de maneira diferente em um contexto legal e estão sujeitos a mudanças ao longo do tempo.

A ética é a filosofia moral que envolve a sistematização, defesa e recomendação de conceitos de conduta correta e incorreta. Em contraste, a privacidade é um conceito vivo construído por meio de negociações contínuas dos limites pessoais com o ambiente ético ao redor. A ética de pesquisa tornou-se um tema relevante nos últimos anos, principalmente a partir de discussões sobre códigos de conduta nas ciências biomédicas, como o genoma humano, e mais recentemente, por meio da \textit{Responsible Research and Innovation} (RRI, ou Pesquisa e Inovação Responsável) promovida pela Comissão Europeia\footnote{http://ec.europa.eu/programmes/horizon2020/en/h2020-
section/responsible-research-innovation}.

Os princípios éticos básicos para a pesquisa foram estabelecidos nos julgamentos de Nuremberg em 1949, onde foram usados para condenar médicos nazistas por suas atrocidades durante a Segunda Guerra Mundial. O chamado Código de Nuremberg é o primeiro manifesto de ética em pesquisa e contém dez princípios internacionalmente reconhecidos para a experimentação em seres humanos. Desde então, outros documentos como a Declaração de Helsinki \cite{Helsinki} e o Relatório Belmont \cite{belmont} foram desenvolvidos, fornecendo diretrizes éticas para pesquisas envolvendo seres humanos.

%É importante mencionar que a ética em pesquisas geralmente é necessária apenas para "experimentos". Quando um sistema é implementado diretamente e se torna parte da infraestrutura operacional de uma instituição, a aprovação ética nem sempre é buscada. Nesse caso, a implementação do novo sistema deve cumprir as leis de privacidade e proteção de dados de acordo com a legislação nacional.

% \subsubsection{Coleta de dados por questionários educacionais}

Ao se discutir a ética em \textit{Learning Analytics}, é fundamental abordar não apenas as implicações éticas das análises que serão realizadas ao decorrer deste trabalho de conclusão de curso, mas também a forma como os dados foram obtidos. A coleta de dados por questionários educacionais possui um papel crítico nesse contexto, pois envolve a obtenção de informações sensíveis e pessoais que os alunos autodeclaram.

A implementação de sistemas de frequência escolar pode gerar várias questões éticas em relação à proteção de dados dos alunos e professores, conforme estabelecido pela Lei Geral de Proteção de Dados (LGPD) no Brasil \cite{LGPD}. Portanto, é importante que as escolas estabeleçam uma política clara de privacidade e proteção de dados, informando os alunos, professores e outros funcionários, incluindo diretores, coordenadores e secretários, sobre quais informações serão coletadas e como serão usadas e protegidas pelo questionário. Isso ajuda a garantir a transparência e a segurança na gestão dos dados dos envolvidos. Além disso, é importante haver uma discussão mais ampla na sociedade sobre quais dados podem ser acessados e por quem. Por exemplo, será que um professor poderia ter acesso aos dados de alunos de outra turma, ministrada por outro professor? Será que pais ou responsáveis podem ter acesso aos dados de estudantes maiores de idade? Uma escola poderia compartilhar informação com outras escolas? Quem poderia ter acesso às respostas sensíveis, como declaração de alunos quanto a casos de abuso e violência familiar? O acesso aos dados anonimizados podem ser utilizados para pesquisas científicas brasileiras? 

A privacidade e segurança dos alunos e professores são preocupações essenciais quando se trata de coleta de dados educacional. Dessa forma, é fundamental que sejam estabelecidos limites claros sobre o acesso e uso desses dados, a fim de garantir que apenas pessoas autorizadas tenham acesso às informações coletadas pelo questionário, como professores, coordenadores pedagógicos e diretores escolares. É importante que essas pessoas tenham uma compreensão clara do propósito da coleta de dados e de suas responsabilidades em relação à proteção dos dados, tornando-se necessária a adoção de políticas e medidas de segurança adequadas, como a criptografia de dados e a autenticação de usuários. A literatura acadêmica destaca a importância da proteção dos dados pessoais em ambientes educacionais e a necessidade de medidas efetivas para garantir a privacidade e segurança desses dados \cite{Amo2021}. 

{No Brasil,} a LGPD estabelece que os dados pessoais devem ser coletados de forma transparente e segura e que o armazenamento e processamento desses dados devem ser feitos com a devida proteção contra vazamentos e uso indevido, o cumprimento da lei requer que as escolas implementem medidas de segurança para proteger os dados pessoais dos estudantes, como a criptografia dos dados, o uso de senhas fortes e a realização de backups frequentes. Além disso, a LGPD estabelece que as escolas devem coletar dados pessoais de forma transparente e informar aos estudantes e seus responsáveis sobre como os dados serão utilizados e protegidos \cite{Ferreira2022}. É necessário um planejamento cuidadoso para garantir a proteção de dados pessoais na educação, especialmente com o aumento do uso de tecnologias digitais em sala de aula.

% \subsection{Dados coletados}

% Tendo as considerações anteriores sobre coleta de dados de forma ética, pode-se afirmar que os dados disponibilizados para a realização deste trabalho foram coletados de forma ética. Isso se dá por serem feitos de forma manual, pelos professores, e posteriormente coletados e pré-processados pelo time de pesquisadores da UFAL.